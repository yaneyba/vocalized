---
tags:
  - vocalized
  - gateway
  - ai-gateway
  - voice-ai
  - pipeline
---
## WORKER IMPLEMENTATION - Part 1

## 4.1 Gateway Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Voice AI Gateway Worker                  │
│                                                             │
│  ┌────────────────┐      ┌──────────────────┐               │
│  │  Request       │─────▶│  Provider        │               │ 
│  │  Handler       │      │  Selector        │               │
│  └────────────────┘      └──────────────────┘               │
│           │                       │                         │
│           │                       ▼                         │
│           │              ┌──────────────────┐               │
│           │              │  Strategy        │               │
│           │              │  Engine          │               │
│           │              └──────────────────┘               │
│           │                       │                         │
│           ▼                       ▼                         │
│  ┌────────────────┐      ┌──────────────────┐               │
│  │  Provider      │      │  Failover        │               │
│  │  Factory       │      │  Manager         │               │
│  └────────────────┘      └──────────────────┘               │
│           │                       │                         │
│           ▼                       ▼                         │
│  ┌─────────────────────────────────────────┐                │
│  │         Provider Implementations        │                │
│  │  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐    │                │
│  │  │11Labs│ │ Vapi │ │Retell│ │Dpgrm │    │                │
│  │  └──────┘ └──────┘ └──────┘ └──────┘    │                │
│  └─────────────────────────────────────────┘                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
              ┌─────────────────────────┐
              │   Durable Object:       │
              │   Provider Health       │
              │   Monitor               │
              └─────────────────────────┘
```

---

## 4.2 Core Types & Interfaces

```typescript
// ============================================
// CORE TYPES
// ============================================

interface Env {
  DB: D1Database;
  KV: KVNamespace;
  PROVIDER_HEALTH_DO: DurableObjectNamespace;
  R2_RECORDINGS: R2Bucket;
  JWT_SECRET: string;
  ELEVENLABS_API_KEY: string;
  VAPI_API_KEY: string;
  DEEPGRAM_API_KEY: string;
  RETELL_API_KEY: string;
}

// Provider interface - all providers must implement
interface VoiceProvider {
  name: string;
  
  // Text-to-speech synthesis
  synthesize(
    text: string,
    config: VoiceConfig
  ): Promise<SynthesisResponse>;
  
  // Speech-to-text transcription
  transcribe(
    audio: ArrayBuffer,
    config: TranscribeConfig
  ): Promise<TranscriptionResponse>;
  
  // Streaming synthesis
  streamSynthesize(
    text: string,
    config: VoiceConfig
  ): ReadableStream;
  
  // Health check
  healthCheck(): Promise<HealthStatus>;
  
  // Cost estimation
  estimateCost(
    operation: 'synthesis' | 'transcription',
    quantity: number
  ): number;
}

// Request/Response types
interface VoiceConfig {
  voiceId: string;
  model?: string;
  speed?: number;
  pitch?: number;
  stability?: number;
  similarityBoost?: number;
  style?: number;
}

interface TranscribeConfig {
  language?: string;
  model?: string;
  punctuate?: boolean;
  diarize?: boolean;
}

interface SynthesisResponse {
  audio: ArrayBuffer | null;
  contentType: string;
  provider: string;
  duration?: number;
  characters?: number;
  cost: number;
  metadata?: any;
}

interface TranscriptionResponse {
  text: string;
  words?: Array<{
    word: string;
    start: number;
    end: number;
    confidence: number;
  }>;
  confidence?: number;
  provider: string;
  cost: number;
}

interface HealthStatus {
  provider: string;
  status: 'healthy' | 'degraded' | 'down';
  latency?: number;
  errorRate?: number;
  lastCheck: number;
  error?: string;
}

// Provider configuration from DB
interface ProviderConfig {
  provider: string;
  is_enabled: boolean;
  priority: number;
  config: any;
}

// Gateway request
interface GatewayRequest {
  workspaceId: string;
  operation: 'synthesize' | 'transcribe' | 'stream';
  text?: string;
  audio?: ArrayBuffer;
  voiceConfig?: VoiceConfig;
  transcribeConfig?: TranscribeConfig;
}

// Custom errors
class ProviderError extends Error {
  constructor(
    message: string,
    public provider: string,
    public statusCode?: number,
    public originalError?: any
  ) {
    super(message);
    this.name = 'ProviderError';
  }
}

class NoProvidersAvailableError extends Error {
  constructor(message: string = 'No healthy providers available') {
    super(message);
    this.name = 'NoProvidersAvailableError';
  }
}
```

---

## 4.3 Provider Implementations

### ElevenLabs Provider

```typescript
class ElevenLabsProvider implements VoiceProvider {
  name = 'elevenlabs';
  private apiKey: string;
  private baseUrl = 'https://api.elevenlabs.io/v1';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async synthesize(
    text: string,
    config: VoiceConfig
  ): Promise<SynthesisResponse> {
    const startTime = Date.now();

    try {
      const response = await fetch(
        `${this.baseUrl}/text-to-speech/${config.voiceId}`,
        {
          method: 'POST',
          headers: {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': this.apiKey
          },
          body: JSON.stringify({
            text,
            model_id: config.model || 'eleven_monolingual_v1',
            voice_settings: {
              stability: config.stability || 0.5,
              similarity_boost: config.similarityBoost || 0.75,
              style: config.style || 0,
              use_speaker_boost: true
            }
          })
        }
      );

      if (!response.ok) {
        const error = await response.text();
        throw new ProviderError(
          `ElevenLabs synthesis failed: ${error}`,
          this.name,
          response.status,
          error
        );
      }

      const audio = await response.arrayBuffer();
      const latency = Date.now() - startTime;

      return {
        audio,
        contentType: 'audio/mpeg',
        provider: this.name,
        characters: text.length,
        cost: this.estimateCost('synthesis', text.length),
        metadata: {
          latency,
          voiceId: config.voiceId,
          model: config.model
        }
      };

    } catch (error) {
      if (error instanceof ProviderError) throw error;
      
      throw new ProviderError(
        `ElevenLabs request failed: ${error.message}`,
        this.name,
        undefined,
        error
      );
    }
  }

  async transcribe(
    audio: ArrayBuffer,
    config: TranscribeConfig
  ): Promise<TranscriptionResponse> {
    throw new ProviderError(
      'ElevenLabs does not support transcription',
      this.name
    );
  }

  streamSynthesize(text: string, config: VoiceConfig): ReadableStream {
    return new ReadableStream({
      async start(controller) {
        try {
          const response = await fetch(
            `${this.baseUrl}/text-to-speech/${config.voiceId}/stream`,
            {
              method: 'POST',
              headers: {
                'Accept': 'audio/mpeg',
                'Content-Type': 'application/json',
                'xi-api-key': this.apiKey
              },
              body: JSON.stringify({
                text,
                model_id: config.model || 'eleven_monolingual_v1',
                voice_settings: {
                  stability: config.stability || 0.5,
                  similarity_boost: config.similarityBoost || 0.75
                }
              })
            }
          );

          if (!response.ok) {
            throw new Error(`Streaming failed: ${response.status}`);
          }

          const reader = response.body?.getReader();
          if (!reader) {
            throw new Error('No stream available');
          }

          while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            controller.enqueue(value);
          }

          controller.close();
        } catch (error) {
          controller.error(error);
        }
      }
    });
  }

  async healthCheck(): Promise<HealthStatus> {
    const startTime = Date.now();

    try {
      const response = await fetch(`${this.baseUrl}/user`, {
        headers: { 'xi-api-key': this.apiKey }
      });

      const latency = Date.now() - startTime;

      return {
        provider: this.name,
        status: response.ok ? 'healthy' : 'degraded',
        latency,
        lastCheck: Date.now()
      };

    } catch (error) {
      return {
        provider: this.name,
        status: 'down',
        error: error.message,
        lastCheck: Date.now()
      };
    }
  }

  estimateCost(
    operation: 'synthesis' | 'transcription',
    quantity: number
  ): number {
    if (operation === 'synthesis') {
      // ElevenLabs: ~$0.30 per 1000 characters
      return (quantity / 1000) * 0.30;
    }
    return 0;
  }
}
```

### Deepgram Provider

```typescript
class DeepgramProvider implements VoiceProvider {
  name = 'deepgram';
  private apiKey: string;
  private baseUrl = 'https://api.deepgram.com/v1';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async synthesize(
    text: string,
    config: VoiceConfig
  ): Promise<SynthesisResponse> {
    const startTime = Date.now();

    try {
      const model = config.model || 'aura-asteria-en';
      
      const response = await fetch(
        `${this.baseUrl}/speak?model=${model}`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Token ${this.apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ text })
        }
      );

      if (!response.ok) {
        const error = await response.text();
        throw new ProviderError(
          `Deepgram synthesis failed: ${error}`,
          this.name,
          response.status,
          error
        );
      }

      const audio = await response.arrayBuffer();
      const latency = Date.now() - startTime;

      return {
        audio,
        contentType: 'audio/mpeg',
        provider: this.name,
        characters: text.length,
        cost: this.estimateCost('synthesis', text.length),
        metadata: {
          latency,
          model
        }
      };

    } catch (error) {
      if (error instanceof ProviderError) throw error;
      
      throw new ProviderError(
        `Deepgram request failed: ${error.message}`,
        this.name,
        undefined,
        error
      );
    }
  }

  async transcribe(
    audio: ArrayBuffer,
    config: TranscribeConfig
  ): Promise<TranscriptionResponse> {
    const startTime = Date.now();

    try {
      const model = config.model || 'nova-2';
      const params = new URLSearchParams({
        model,
        smart_format: 'true',
        punctuate: config.punctuate ? 'true' : 'false',
        diarize: config.diarize ? 'true' : 'false'
      });

      if (config.language) {
        params.append('language', config.language);
      }

      const response = await fetch(
        `${this.baseUrl}/listen?${params.toString()}`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Token ${this.apiKey}`,
            'Content-Type': 'audio/wav'
          },
          body: audio
        }
      );

      if (!response.ok) {
        const error = await response.text();
        throw new ProviderError(
          `Deepgram transcription failed: ${error}`,
          this.name,
          response.status,
          error
        );
      }

      const data = await response.json();
      const latency = Date.now() - startTime;

      const transcript = data.results.channels[0].alternatives[0];

      return {
        text: transcript.transcript,
        words: transcript.words,
        confidence: transcript.confidence,
        provider: this.name,
        cost: this.estimateCost('transcription', audio.byteLength),
        metadata: {
          latency,
          model
        }
      };

    } catch (error) {
      if (error instanceof ProviderError) throw error;
      
      throw new ProviderError(
        `Deepgram request failed: ${error.message}`,
        this.name,
        undefined,
        error
      );
    }
  }

  streamSynthesize(text: string, config: VoiceConfig): ReadableStream {
    return new ReadableStream({
      async start(controller) {
        try {
          const model = config.model || 'aura-asteria-en';
          
          const response = await fetch(
            `${this.baseUrl}/speak?model=${model}`,
            {
              method: 'POST',
              headers: {
                'Authorization': `Token ${this.apiKey}`,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({ text })
            }
          );

          if (!response.ok) {
            throw new Error(`Streaming failed: ${response.status}`);
          }

          const reader = response.body?.getReader();
          if (!reader) {
            throw new Error('No stream available');
          }

          while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            controller.enqueue(value);
          }

          controller.close();
        } catch (error) {
          controller.error(error);
        }
      }
    });
  }

  async healthCheck(): Promise<HealthStatus> {
    const startTime = Date.now();

    try {
      const response = await fetch(`${this.baseUrl}/projects`, {
        headers: { 'Authorization': `Token ${this.apiKey}` }
      });

      const latency = Date.now() - startTime;

      return {
        provider: this.name,
        status: response.ok ? 'healthy' : 'degraded',
        latency,
        lastCheck: Date.now()
      };

    } catch (error) {
      return {
        provider: this.name,
        status: 'down',
        error: error.message,
        lastCheck: Date.now()
      };
    }
  }

  estimateCost(
    operation: 'synthesis' | 'transcription',
    quantity: number
  ): number {
    if (operation === 'synthesis') {
      // Deepgram TTS: ~$0.015 per 1000 characters
      return (quantity / 1000) * 0.015;
    } else {
      // Deepgram STT: ~$0.0043 per minute
      // Assume 16kHz, 16-bit audio
      const minutes = quantity / (16000 * 2 * 60);
      return minutes * 0.0043;
    }
  }
}
```

### Vapi Provider

```typescript
class VapiProvider implements VoiceProvider {
  name = 'vapi';
  private apiKey: string;
  private baseUrl = 'https://api.vapi.ai';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async synthesize(
    text: string,
    config: VoiceConfig
  ): Promise<SynthesisResponse> {
    // Vapi is primarily for live calls, not direct synthesis
    // Return metadata about call setup
    
    try {
      const response = await fetch(`${this.baseUrl}/call`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          assistant: {
            voice: {
              provider: '11labs',
              voiceId: config.voiceId
            },
            model: {
              provider: 'openai',
              model: 'gpt-4'
            },
            firstMessage: text
          }
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new ProviderError(
          `Vapi call creation failed: ${error}`,
          this.name,
          response.status,
          error
        );
      }

      const data = await response.json();

      return {
        audio: null,
        contentType: 'application/json',
        provider: this.name,
        cost: this.estimateCost('synthesis', text.length),
        metadata: {
          callId: data.id,
          status: data.status
        }
      };

    } catch (error) {
      if (error instanceof ProviderError) throw error;
      
      throw new ProviderError(
        `Vapi request failed: ${error.message}`,
        this.name,
        undefined,
        error
      );
    }
  }

  async transcribe(
    audio: ArrayBuffer,
    config: TranscribeConfig
  ): Promise<TranscriptionResponse> {
    throw new ProviderError(
      'Vapi uses underlying providers for transcription',
      this.name
    );
  }

  streamSynthesize(text: string, config: VoiceConfig): ReadableStream {
    throw new ProviderError(
      'Vapi uses WebRTC, not HTTP streaming',
      this.name
    );
  }

  async healthCheck(): Promise<HealthStatus> {
    const startTime = Date.now();

    try {
      const response = await fetch(`${this.baseUrl}/call`, {
        headers: { 'Authorization': `Bearer ${this.apiKey}` }
      });

      const latency = Date.now() - startTime;

      return {
        provider: this.name,
        status: response.ok ? 'healthy' : 'degraded',
        latency,
        lastCheck: Date.now()
      };

    } catch (error) {
      return {
        provider: this.name,
        status: 'down',
        error: error.message,
        lastCheck: Date.now()
      };
    }
  }

  estimateCost(
    operation: 'synthesis' | 'transcription',
    quantity: number
  ): number {
    // Vapi: ~$0.05 per minute
    // Estimate ~150 words per minute, ~5 chars per word
    const estimatedMinutes = quantity / (150 * 5);
    return estimatedMinutes * 0.05;
  }
}
```

### Retell Provider

```typescript
class RetellProvider implements VoiceProvider {
  name = 'retell';
  private apiKey: string;
  private baseUrl = 'https://api.retellai.com';

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async synthesize(
    text: string,
    config: VoiceConfig
  ): Promise<SynthesisResponse> {
    // Similar to Vapi - primarily for live calls
    try {
      const response = await fetch(`${this.baseUrl}/create-web-call`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          agent_id: config.voiceId,
          metadata: { first_message: text }
        })
      });

      if (!response.ok) {
        const error = await response.text();
        throw new ProviderError(
          `Retell call creation failed: ${error}`,
          this.name,
          response.status,
          error
        );
      }

      const data = await response.json();

      return {
        audio: null,
        contentType: 'application/json',
        provider: this.name,
        cost: this.estimateCost('synthesis', text.length),
        metadata: {
          callId: data.call_id,
          accessToken: data.access_token
        }
      };

    } catch (error) {
      if (error instanceof ProviderError) throw error;
      
      throw new ProviderError(
        `Retell request failed: ${error.message}`,
        this.name,
        undefined,
        error
      );
    }
  }

  async transcribe(
    audio: ArrayBuffer,
    config: TranscribeConfig
  ): Promise<TranscriptionResponse> {
    throw new ProviderError(
      'Retell handles transcription internally',
      this.name
    );
  }

  streamSynthesize(text: string, config: VoiceConfig): ReadableStream {
    throw new ProviderError(
      'Retell uses WebRTC, not HTTP streaming',
      this.name
    );
  }

  async healthCheck(): Promise<HealthStatus> {
    const startTime = Date.now();

    try {
      const response = await fetch(`${this.baseUrl}/list-agents`, {
        headers: { 'Authorization': `Bearer ${this.apiKey}` }
      });

      const latency = Date.now() - startTime;

      return {
        provider: this.name,
        status: response.ok ? 'healthy' : 'degraded',
        latency,
        lastCheck: Date.now()
      };

    } catch (error) {
      return {
        provider: this.name,
        status: 'down',
        error: error.message,
        lastCheck: Date.now()
      };
    }
  }

  estimateCost(
    operation: 'synthesis' | 'transcription',
    quantity: number
  ): number {
    // Retell: ~$0.04 per minute
    const estimatedMinutes = quantity / (150 * 5);
    return estimatedMinutes * 0.04;
  }
}
```

---

## 4.4 Provider Factory

```typescript
class ProviderFactory {
  static create(providerName: string, apiKey: string): VoiceProvider {
    switch (providerName.toLowerCase()) {
      case 'elevenlabs':
        return new ElevenLabsProvider(apiKey);
      
      case 'deepgram':
        return new DeepgramProvider(apiKey);
      
      case 'vapi':
        return new VapiProvider(apiKey);
      
      case 'retell':
        return new RetellProvider(apiKey);
      
      // Add more providers here
      
      default:
        throw new Error(`Unknown provider: ${providerName}`);
    }
  }

  static getSupportedProviders(): string[] {
    return ['elevenlabs', 'deepgram', 'vapi', 'retell'];
  }
}
```

---

## 4.5 Selection Strategies

```typescript
// ============================================
// PROVIDER SELECTION STRATEGIES
// ============================================

interface SelectionStrategy {
  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null;
}

class CostOptimizedStrategy implements SelectionStrategy {
  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null {
    
    // Filter to healthy, enabled providers
    const available = providers.filter(p => {
      const health = healthMap.get(p.provider);
      return p.is_enabled && health?.status === 'healthy';
    });

    if (available.length === 0) return null;

    // Sort by estimated cost (lowest first)
    available.sort((a, b) => {
      const costA = this.estimateRequestCost(a, request);
      const costB = this.estimateRequestCost(b, request);
      return costA - costB;
    });

    return available[0];
  }

  private estimateRequestCost(
    provider: ProviderConfig,
    request: GatewayRequest
  ): number {
    // Simplified cost per character/byte
    const costs: Record<string, number> = {
      elevenlabs: 0.30,  // per 1000 chars
      deepgram: 0.015,   // per 1000 chars
      vapi: 0.05,        // per minute (estimated)
      retell: 0.04       // per minute (estimated)
    };

    const baseCost = costs[provider.provider] || 0.10;

    if (request.operation === 'synthesize' && request.text) {
      return (request.text.length / 1000) * baseCost;
    }

    return baseCost;
  }
}

class QualityFirstStrategy implements SelectionStrategy {
  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null {
    
    // Filter to healthy, enabled providers
    const available = providers.filter(p => {
      const health = healthMap.get(p.provider);
      return p.is_enabled && health?.status === 'healthy';
    });

    if (available.length === 0) return null;

    // Quality ranking (subjective, can be configurable)
    const qualityRank: Record<string, number> = {
      elevenlabs: 5,
      vapi: 4,
      retell: 4,
      deepgram: 3
    };

    // Sort by quality (highest first)
    available.sort((a, b) => {
      const qualityA = qualityRank[a.provider] || 0;
      const qualityB = qualityRank[b.provider] || 0;
      return qualityB - qualityA;
    });

    return available[0];
  }
}

class LatencyOptimizedStrategy implements SelectionStrategy {
  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null {
    
    // Filter to healthy, enabled providers
    const available = providers.filter(p => {
      const health = healthMap.get(p.provider);
      return p.is_enabled && health?.status === 'healthy';
    });

    if (available.length === 0) return null;

    // Sort by latency (lowest first)
    available.sort((a, b) => {
      const healthA = healthMap.get(a.provider);
      const healthB = healthMap.get(b.provider);
      const latencyA = healthA?.latency || 9999;
      const latencyB = healthB?.latency || 9999;
      return latencyA - latencyB;
    });

    return available[0];
  }
}

class SpecificProviderStrategy implements SelectionStrategy {
  constructor(private preferredProvider: string) {}

  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null {
    
    const provider = providers.find(p => {
      const health = healthMap.get(p.provider);
      return (
        p.provider === this.preferredProvider &&
        p.is_enabled &&
        health?.status === 'healthy'
      );
    });

    return provider || null;
  }
}

class CustomRulesStrategy implements SelectionStrategy {
  constructor(private rules: any[]) {}

  selectProvider(
    providers: ProviderConfig[],
    healthMap: Map<string, HealthStatus>,
    request: GatewayRequest
  ): ProviderConfig | null {
    
    // Filter to healthy, enabled providers
    const available = providers.filter(p => {
      const health = healthMap.get(p.provider);
      return p.is_enabled && health?.status === 'healthy';
    });

    if (available.length === 0) return null;

    // Evaluate rules in order
    for (const rule of this.rules) {
      if (this.evaluateRule(rule, request)) {
        const provider = available.find(p => p.provider === rule.provider);
        if (provider) return provider;
      }
    }

    // Fallback to cost-optimized
    const fallback = new CostOptimizedStrategy();
    return fallback.selectProvider(providers, healthMap, request);
  }

  private evaluateRule(rule: any, request: GatewayRequest): boolean {
    // Example rules:
    // { condition: 'text_length', operator: '>', value: 1000, provider: 'deepgram' }
    // { condition: 'operation', operator: '==', value: 'transcribe', provider: 'deepgram' }
    
    switch (rule.condition) {
      case 'text_length':
        if (!request.text) return false;
        return this.compareValues(
          request.text.length,
          rule.operator,
          rule.value
        );
      
      case 'operation':
        return this.compareValues(
          request.operation,
          rule.operator,
          rule.value
        );
      
      // Add more conditions as needed
      
      default:
        return false;
    }
  }

  private compareValues(
    actual: any,
    operator: string,
    expected: any
  ): boolean {
    switch (operator) {
      case '==': return actual === expected;
      case '!=': return actual !== expected;
      case '>': return actual > expected;
      case '>=': return actual >= expected;
      case '<': return actual < expected;
      case '<=': return actual <= expected;
      default: return false;
    }
  }
}

// Strategy factory
class StrategyFactory {
  static create(
    strategyType: string,
    config?: any
  ): SelectionStrategy {
    switch (strategyType) {
      case 'cost_optimized':
        return new CostOptimizedStrategy();
      
      case 'quality_first':
        return new QualityFirstStrategy();
      
      case 'latency_optimized':
        return new LatencyOptimizedStrategy();
      
      case 'specific':
        return new SpecificProviderStrategy(config.provider);
      
      case 'custom':
        return new CustomRulesStrategy(config.rules);
      
      default:
        return new CostOptimizedStrategy();
    }
  }
}
```

---

**Continue with Part 2 of Voice AI Gateway (Failover, Health Monitoring, Main Gateway Class)?**
#vocalized